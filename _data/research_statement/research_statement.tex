\documentclass[11pt,a4paper,sans]{moderncv} 

\moderncvstyle{casual}                             % style options are 'casual' (default), 'classic', 'oldstyle' and 'banking'
\moderncvcolor{blue}                               % color options 'blue' (default), 'orange', 
\usepackage[utf8]{inputenc}                       % if you are not using xelatex ou lualatex, replace 
\usepackage[scale=0.75]{geometry}
\firstname{Research} % Your first name
\familyname{Statement} % Your last name

% All information in this block is optional, comment out any lines you don't need
\title{Hirak Sarkar}
\address{5812 Quebec St}{Berwyn Heights, MD-20740}
\mobile{(631) 520 8131}
\email{hsarkar@umd.edu}
\homepage{www.hiraksarkar.com}{www.hiraksarkar.com}
\renewcommand*{\bibliographyitemlabel}{[\arabic{enumiv}]}% CONSIDER REPLACING THE ABOVE BY THIS
\begin{document}
\makecvtitle
\setlength{\parindent}{5ex}
RNA-seqencing has become the de-facto standard for measuring transcript and gene-level expression across different cells, tissues, organisms and species. Given the tremendous popularity of the RNA-seq assay, there are numerous tools that are designed to store (efficient disk usage), process (map or align), and analyse (quantification, differential expression etc.) this data.

\setlength{\parindent}{5ex}
Throughout my doctoral studies, I discovered interesting challenges in each of these steps, and proposed solutions that either improved the performance of existing methods or introduced a new approach altogether. To be more specific, I studied the nature of sequence redundancy in RNA-seq dataset. I observed that the presence of identical sequences in the RNA-seq experiments, often originating from shared exons or paralogous references etc, plays a major role in many challenges related to RNA-seq data analysis. Through different research projects, I tried to both address the challenges of multi-mapping~\cite{quark,pufferfish,selaln} in mapping and quantification of RNA-seq data and, simultaneously have shown ways to turn this challenge into an opportunity to increase the efficiency of the computational pipeline~\cite{terminus,rapclust}.

\section{Published Research}
\setlength{\parindent}{5ex}
 I introduced Quark \cite{quark}, a semi reference-based compression algorithm for RNA-seq data, which leverages the shared sequences present in the raw fastq files. The core compression algorithm makes use of read level ``equivalence classes'', a derivative of another popular light-weight algorithm ``Quasi-mapping'' that I co-authored~\cite{rapmap}. Quark stores parts of reference only once that are redundantly present multiple times in the given read dataset, represented in the form of the sequence that induces these equivalence classes. Although the reference is required for compressing the reads, it is not required in the phase of decompression, effectively making the algorithm independent of the reference used for compression (this is where the moniker semi reference-based comes from). Later, I contributed to designing Pufferfish~\cite{pufferfish}, a succinct graph-based indexing scheme for RNA-seq data, that, right now, serves as the basic backbone for the principle mapper in the widely popular quantification tool Salmon~\cite{salmon}. The multi-mappable reads resulting from the sequence redundancy can also lead to uncertain quantification estimates. I addressed this problem in the recently published tool Terminus~\cite{terminus}, where we proposed a solution that produces groups of transcripts when read-level evidence is insufficient to provide robust quantification estimates of individual transcripts. Moreover, we have shown that such groups of transcripts can capture biological information (such as gene families) even though the tool itself has no information about underlying annotation.

\setlength{\parindent}{5ex}
While bulk RNA-seq provides reproducible, highly-sensitive transcript-level expression measurements, the individual signals from different cells are lost. Single-cell RNA-seq technology, which has become widely popular in the last few years, enables cellular level resolution of RNA-seq expression profiling. As a result, a myriad of publicly available datasets are now available providing gene expression from multiple (ranging from thousands to millions) cells over many organs and tissues. To aid the analysis of these huge datasets, new computational techniques are developed extending the existing tools for bulk RNA-seq datasets. I observed that, in the absence of ground truth knowledge, it is often difficult to assess the accuracy of such tools. This lead me to develop a sequence-level simulator Minnow~\cite{minnow} for droplet-based single-cell RNA-seq data. Minnow can mimic the pattern of sequence level multi-mapping of real-world datasets, and is capable of simulating reads from many thousands of cells in a multi-threaded fashion. I have also contributed to improving other methodologies~\cite{mappingsmatter,rapclust,alevin2,selaln} that further enhanced and improved the performance of existing bulk and single-cell RNA-seq pipelines.

\section{Future Research}
Although my focus has been the analysis of RNA-seq datasets in both the single-cell and bulk context, I feel it only captures one dimension of the multi-modal and complex cell heterogeneity that exists. Other data modalities, such as DNA methylation (GEM-seq), chromatin accessibility (single-cell ATAC-seq), and spatial information (FISH-seq) not only mitigate the caveat of one protocol (such as missing expression values from one of the assays) but can also validate the conclusions drawn from the data.  With this goal in mind, I aim to design computational pipelines that can analyze and integrate sequence-level data from multiple sources.  A typical data processing pipeline for a particular assay runs independently. Therefore, even when the results from another assay are present from a matched dataset, this information is not being utilized. A principled method that captures the inherent conflicts in the results from different assays could take advantage of this and further improve the accuracy and robustness of the computational estimates being made. The theoretical underpinning of such a representation can be achieved by defining a transcriptional ``latent space'', where the set of observed variables can represent the assays at our disposal. On a conceptual level, this idea exists in the field of natural language processing and image processing, widely known as ``domain adaptation''~\cite{daume2009frustratingly,ganin2014unsupervised}. Although similar efforts have been made in single-cell multi-omics dataset~\cite{liu2019jointly,amodio2018magan,eraslan2019deep}, such approaches lack generalizability and interpretability. I believe building a large scale repository of the matched publicly-available multi-omics dataset, along with the corresponding transcriptional latent spaces (via both existing and newly proposed methods) can improve the usability and accuracy of the multi-modal analysis.

%Although my focus has been the analysis of RNA-seq datasets in both the single-cell and bulk context, I feel it only captures one dimension of the multi-modal and complex cell heterogeneity that exists. Other data modalities, such as DNA methylation (GEM-seq), chromatin accessibility (single-cell ATAC-seq), and spatial information (FISH-seq) not only mitigate the caveat of one protocol (such as missing expression values from one of the assays) but can also validate the conclusions drawn from the data.  With this goal in mind, I aim to design computational pipelines that can analyze and integrate sequence-level data from multiple sources.  A typical data processing pipeline for a particular assay runs independently. Therefore, even when the results from another assay are present from a matched dataset, this information is not being utilized. A principled method that captures the inherent conflicts in the results from different assays could take advantage of this and further improve the accuracy and robustness of the computational estimates being made. The theoretical underpinning of such a representation can be achieved by defining a transcriptional ``latent space'', where the set of observed variables can represent the assays at our disposal. One inspiring method in the same direction is LIGER~\cite{welch2019single}, where this latent space is obtained from an iterative algorithm and referred to as ``metagenes''. On a conceptual level, the idea of shared subspace is well studied in the field of natural language processing and image processing, widely known as ``domain adaptation''~\cite{daume2009frustratingly,ganin2014unsupervised}. Although similar efforts have been made in single-cell multi-omics dataset~\cite{liu2019jointly,amodio2018magan,eraslan2019deep}, such approaches lack generalizability and interpretability. I believe building a large scale repository of the matched publicly-available multi-omics dataset, along with the corresponding transcriptional latent spaces (via both existing and newly proposed methods) can improve the usability and accuracy of the multi-modal analysis.



%Although my focus has been the analysis of RNA-seq datasets in both the single-cell and bulk context, I feel it only captures one dimension of the multi-modal and complex cell heterogeneity that exists. Other data modalities, such as DNA methylation (GEM-seq), chromatin accessibility (single-cell ATAC-seq), and spatial information (FISH-seq) not only mitigate the caveat of one protocol (such as missing expression values from one of the assays) but can also validate the conclusions drawn from the data. 
% \setlength{\parindent}{5ex}
% I aim to design computational pipelines that can analyze and integrate sequence-level data from multiple sources. A typical data processing pipeline for a particular assay runs independently. Therefore, even when the results from another assay are present from a matched dataset, this information is not being utilized. A principled method that captures the inherent conflicts in the results from different assays could take advantage of this and further improve the accuracy and robustness of the computational estimates being made. The theoretical underpinning of such a representation can be achieved by defining a transcriptional ``latent space'', where the set of observed variables can represent the assays at our disposal. On a conceptual level, this idea exists in the field of natural language processing and image processing, widely known as ``domain adaptation''~\cite{daume2009frustratingly,ganin2014unsupervised}. Although similar efforts have been made in single-cell multi-omics dataset~\cite{liu2019jointly,amodio2018magan,eraslan2019deep}, such approaches lack generalizability and interpretability. I believe building a large scale repository of matched publicly-available multi-omics dataset, along with the corresponding transcriptional latent spaces (via both existing and newly proposed methods) can improve the usability and accuracy of multi-modal analysis.
\clearpage
\bibliographystyle{plain}
\bibliography{pub}                  
\end{document}
